{
    "title": "[KAIST SoC Colloquium] 6／15 4pm, Prof. Seungwon Hwang, ˝Knowledge for Language Understanding˝",
    "date": "2020-06-15T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=9208&page=1&skey=&svalue=&menu=86",
    "content": "title:[KAIST SoC Colloquium] 6／15 4pm, Prof. Seungwon Hwang, ˝Knowledge for Language Understanding˝ date:2020-06-15T00:00:00Z link:https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=9208&page=1&skey=&svalue=&menu=86 content:Speaker : Prof. Seungwon Hwang Time: 16:00, June 15, 2020 Via Zoom due to COVID-19 ( Link: https://yonsei.zoom.us/j/5253312674 ) Language : English Abstract Deep learning models for NLP often tackle each task in isolation, requiring a large number of training examples and works well only on well-defined and narrow tasks. Meanwhile, we face the challenge of sample-efficient transfer, e.g., when supporting poor-resource languages or bootstrapping AI products before enough training data are acquired. This talk discusses our recent work leveraging knowledge for generalizing from small training resources or transferring from other tasks. Specifically, we overview our recent papers for this purpose. Details can be found from http://dilab.yonsei.ac.kr Bio Prof. Seung-won Hwang is a Professor of Computer Science at Yonsei University. Prior to joining Yonsei, she had been an Associate Professor at POSTECH for 10 years, after her PhD from UIUC. Her recent research interest has been data and language understanding and intelligence, led to 100＋ publication at top-tier AI, DB/DM, and NLP venues, including ACL, AAAI, IJCAI, NAACL, SIGMOD, VLDB, and ICDE. She has received best paper runner-up and outstanding collaboration award from WSDM and Microsoft Research respectively. If you want to get more information about the colloquium, please refer to colloquium page: https://cs.kaist.ac.kr/colloquium/ . location: Online(zoom) tag:csweb.calendar",
    "location": " Online(zoom)",
    "tag": "csweb.calendar",
    "id": 26
}