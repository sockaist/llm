{
    "title": "[ERC Seminar＃15] 6／16 (Thur) 4 pm, Hongseok Namkoong(Assistant Professor,Columbia Univ.) , “Robust Counterfactual Learning of Operational Decisions ”",
    "date": "2022-06-16T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=10308&page=1&skey=&svalue=&menu=86",
    "content": "title:[ERC Seminar＃15] 6／16 (Thur) 4 pm, Hongseok Namkoong(Assistant Professor,Columbia Univ.) , “Robust Counterfactual Learning of Operational Decisions ” date:2022-06-16T00:00:00Z link:https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=10308&page=1&skey=&svalue=&menu=86 content:1. Place : - Offline : E2-2 B/D Lecture room (#1501) - Online : https://kaist.zoom.us/j/86703268976 (Meeting ID: 867 0326 8976) 2. Speaker : Hongseok Namkoong(Assistant Professor, Columbia Univ., Graduate School of Business, Division of Decision, Risk, and Operations) 3. Title: Robust Counterfactual Learning of Operational Decisions 4. Abstract: The explosive growth in previously collected data in sequential decision-making (reinforcement learning) problems presents opportunities for learning timely and optimal decisions in healthcare, manufacturing, and online marketplaces. Counterfactual reasoning—analyzing the ceteris paribus effect of a decision—is key to learning optimal decisions but due to the presence of selection bias in the collected data, standard machine learning-based approaches cannot learn causal relationships. These approaches yield spurious conclusions due to unrecorded confounders that simultaneously impact observed decisions and their outcomes, e.g., doctors often prescribe drugs to those who can withstand their side effects, leading to overly optimistic estimates of their benefits. As rigorous empirical evaluation is critical for engineering progress, we develop robust counterfactual evaluation methods that ensure decision policies perform well even under unobserved confounding. We develop personalized worst-case bounds under a realistic notion of confounding and derive a scalable loss minimization method for estimating them. Then, we propose a related worst-case sensitivity approach for aggregate rewards by developing a semiparametric framework that extends/bounds the widely adopted doubly robust estimator. Our estimator enjoys optimal rates of convergence and allows robust evaluations of decision policies on real and simulated problems. Link: main paper for causal inference and extensions to sequential decision-making. 5. Bio: Hongseok Namkoong is an Assistant Professor in the Decision, Risk, and Operations division at Columbia Business School. His research interests lie at the interface of machine learning, operations research, and causal inference, with a particular emphasis on developing reliable machine learning methods for decision-making problems. Hong is a recipient of several awards and fellowships, including best paper awards at the Neural Information Processing Systems conference and the International Conference on Machine Learning (runner-up), and the best student paper award from the INFORMS Applied Probability Society. Hong received his Ph.D. from Stanford University where he was jointly advised by John Duchi and Peter Glynn, and worked as a research scientist at Facebook Core Data Science before joining Columbia. 6. Language : English location: E2-2 B/D Lecture room (#1501) tag:csweb.calendar",
    "location": " E2-2 B/D Lecture room (#1501)",
    "tag": "csweb.calendar",
    "id": 179
}