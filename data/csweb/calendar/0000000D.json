{
    "title": "[KAIST SoC Colloquium] 4／13, 4pm, 박종세 (Jongse Park) (KAIST ／ Professor)",
    "date": "2020-04-13T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=9119&page=1&skey=&svalue=&menu=86",
    "content": "title:[KAIST SoC Colloquium] 4／13, 4pm, 박종세 (Jongse Park) (KAIST ／ Professor) date:2020-04-13T00:00:00Z link:https://cs.kaist.ac.kr/board/view?bbs_id=events&bbs_sn=9119&page=1&skey=&svalue=&menu=86 content:Speaker : 박종세 (Jongse Park) (KAIST / Professor) Abstract : As the computational demand of emerging applications rapidly increases, the benefits of conventional general-purpose solutions are diminishing. Recently, community has started exploring hardware specialization as a path forward. However, specialization creates a tension between performance and programmability. (1) Programmers need to delve into the details of specialized hardware, and/or (2) they need to perform low-level programming. Hence, it is imperative to (1) deliver large gains in performance and efficiency, (2) while retaining automation and productivity through high-level programming abstractions. Achieving these conflicting objectives is a crucial challenge to place specialization in a position of practical utility. To address this challenge, my research portfolio breaks the traditional abstractions and offers algorithm-driven computing stacks, which make specialized hardware programmable from high-level languages. I have primarily focused on two paradigms of specialization: approximation and acceleration. For approximation, I will present AxGames, a crowdsourcing and gamification solution that automatically examines the end users’ perspective on the effect of approximation and statistically determines the quality target. For acceleration, the talk will focus on INCEPTIONN, a full-computing stack that leverages algorithmic insights and in-network accelration to build a distributed DNN training system. INCEPTIONN reduces the communication time by 70.9∼80.7％ and offers 2.2∼3.1× speedup over the conven- tional training system, while achieving the same level of accuracy. Bio : Jongse Park is an assistant professor at KAIST School of Computing and a faculty member of Computer Architecture and Systems (CASys) laboratory. Jongse joined KAIST in December 2019. Before joining KAIST, he was the lead acceleration solution architect in Bigstream Solutions Inc., where he led the commercialization of his PhD research, which aims to develop the full-stack solution to accelerate the Deep Learning inference. Prof. Park obtained his Ph.D. from the School of Computer Science at Georgia Institute of Technology in 2018 and his M.S. from School of Computing at KAIST in 2012. He is interested in interdisciplinary research that brings computer architecture, distributed and/or heterogenous systems, and machine learning together. Currently, his primary research goal is to design and build hardware-software co-designed computing stacks specialized for machine learning, which offers performance, efficiency, and programmability, simultaneously. Language : English Zoom url : https://kaist.zoom.us/j/957316399?pwd=QnQzc3Q4SktCTndETm9IRUIxRWUxZz09 location: Online(zoom) tag:csweb.calendar",
    "location": " Online(zoom)",
    "tag": "csweb.calendar",
    "id": 13
}