{
    "title": "[특별인터뷰] ‘일상 대화 AI 챗봇 기술 현황과 앞으로의 과제’...＇한국어 블렌더봇＇, KAIST 전산학부 차미영 교수에 듣는다！",
    "date": "2022-07-18T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=news&bbs_sn=10348&page=6&skey=subject&svalue=&menu=83",
    "content": "출처 :\n인공지능신문\n(2022.07.17) ｜ 최광민 기자\n지난해 7월 메타(구 페이스북)가 혁신적인 AI 챗봇 ‘블렌더봇 2.0BlenderBot 2.0)’ 오픈 소스로 공개했다. GPT-3와 메타 AI의 블렌더 봇 첫 번째 버전(1.0)과 같은 AI 언어 생성 모델은 적어도 진행 중인 대화의 맥락에서 자신을 명확하게 표현하고 현실적으로 보이는 텍스트를 생성할 수 있다.\n하지만, 그들은 매우 짧은 기억력과 정적인 정보로 이전에 학습된 것에 한정된다는 과제를 가지고 있다. 즉, 그들은 이전에 학습한 것에 국한된다는 것으로 결코 추가적인 지식을 얻을 수 없다는 것이다. 게다가 그들은 과거의 인기 있는 TV쇼와 영화에 대해 알고 있지만, 미국의 슈퍼히어로 드라마 완다비전(WandaVision)과 같은 새로운 시리즈에 대해서는 전혀 알지 못한다.\n다시 말해, 어제 GPT-3나 블렌더봇(1.0)에 뭔가 얘기했다면 오늘 대화에서는 어제의 기억을 잊어버린다. 여기에, 더 안좋은 것은 알고리즘의 결함 때문에 모델들은 환각적인 지식(Infamously Hallucinate knowledge)으로 즉, 정확하지 않은 정보를 자신 있게 이야기한다는 것이다.\n이에 메타 AI는 지속적으로 접속할 수 있는 장기기억장치(Long-Memory)를 구축하고 현재까지의 어떤 모델보다 실시간 인터넷 검색과 거의 모든 주제에 대한 정교한 대화 등을 동시에 할 수 있는 성능이 뛰어나고 더 인간적인 느낌을 줄 수 있는 새로운 인공지능 챗봇 '블렌더봇 2.0 (BlenderBot 2.0)' 모델과 데이터 세트를 지난해 7월 오픈소스로 공개한 것이다.\n최근, 과학기술정보통신부(장관 이종호)가 주관하고 한국지능정보사회진흥원(이하 NIA)이 추진하는 '2022년도 인공지능 학습 데이터 구축사업'에서 메타의 AI 챗봇 블렌더봇 2.0BlenderBot 2.0)의 한국형 버전으로 '한국어 블렌더 봇 데이터 구축' 과제를 심심이(대표 최정회)와 협약을 체결하고 수행기관으로 본격 진행하고 있다.\nNIA의 이 사업은 일상대화 챗봇에서 나타나는 문제점들, 즉 일관된 정체성을 유지하지 못하거나 외부 세계의 새로운 정보를 반영하지 못하는 점, 상대의 감정에 적절하게 공감을 하지 못하는 점 등을 해결하는 것을 목표로 한다.<편집자 주>\n이에 본지는 ‘일상 대화 AI 챗봇 기술 현황과 앞으로의 과제’란 주제로 이 사업 '한국어 블렌더 봇 데이터 구축'에 대한 세부적인 내용과 기술과 비전을 이 사업의 수행기관인 심심이와 한국인공지능협회(회장 김현철) 협조로 관련 자문위원과 인공지능 챗봇 및 언어 인공지능 관련 최고 전문가를 찾아 담아본다.\n그 첫 번째로 AI윤리, 신뢰가능 AI, 클라우드 컴퓨팅, 소셜미디어 등 IT 전문가이자 전직 교수로 삼성전자, 다음커뮤니케이션에서 근무하였으며, 현재 테크프론티어 한상기 대표가 인터뷰어로 나서, 인공지능·정보서비스, 소셜 컴퓨팅, 인터랙티브 컴퓨팅의 국내 최고 전문가 중 한명이자 이 사업의 자문위원으로 위촉된 KAIST 전산학부 차미영 교수를 만나보았다.\n특히, 차미영 교수는 데이터 과학, 네트워크 과학, 인공지능을 활용한 계산사회과학으로 가짜뉴스, 빈곤예측, 이상거래 탐지 등의 중요한 사회 문제를 다룬 차 교수의 논문은 그간 18,000회 이상 피인용 되었다. 차 교수는 아시아 최초로 미국 페이스북(현 메타) 본사 데이터 사이언스 팀의 초빙교수로 근무한 경험이 있으며, 정보과학회 젊은정보과학자상, AAAI ICWSM Test of Time Award, 과기부 장관표창의 수상자이다. 현재 그는 기초과학연구원 데이터사이언스 그룹을 이끌며 겸직 중이다.\nQ . 현재, 진행하고 있는 주요 연구 분야와 그동안 성과와 비전에 대해서\nA . 저희가 하는 연구는 데이터 사이언스 입니다. 전산이나 공학에서 굉장히 많은 알고리듬이 빠르게 개발되고 있고 정말 초격차로 기술들이 계속 나오고 있는데, 현재 사회의 문제를 해결하는 데 직접 활용이 되는 케이스는 너무 적습니다.\n현실 사회에서 어렵고 복잡한 문제에 좋은 알고리즘이 쓰여야 되는데 그러지 못하는 것이 안타까웠죠 그래서 저는 최첨단 알고리즘을 어려운 사회 과학 문제에 사용하는 가교 역할을 하고 있어요.\n가장 대표적으로는 가짜 뉴스 탐지에 관한 연구가 있습니다. 가짜 뉴스나 루머의 확산 패턴을 알면 그 패턴을 딥러닝으로 학습을 하고 그다음에 탐지를 할 수 있고요 그에 따른 대응 전략을 짤 수 있어요.\n예를 들면, 어떤 사용자를 정보의 흐름에서 차단한 다라든지 등 여러 가지 대응 전략을 짤 수 있습니다. 비슷한 문제로 탈세범 잡는 그런 알고리즘도 개발을 했어요.\n특히, 탈세범 잡을 때는 설명가능한 인공지능(XAI)이 정말 중요하더라고요 왜냐하면 알고리즘이 아주 잘 동작해도 설명을 안 해주면 사용자가 안 쓰려고 해요. 예로 세관원들은 블랙박스 모델보다도 차라리 설명력이 있고 정확도가 조금 떨어지더라도 설명을 하는 걸 달라고 합니다.\n현재, XAI는 관세청 및 세계 관세기구(WCO)하고 협업을 하고 있습니다. 대신, 국내외 훌륭한 랩에서 만들어낸 최신의 알고리즘을 사용하고 있습니다. 요즘은 연구 결과를 깃허브 등으로 다 공개하기 때문에 최신 모델을 절차를 거쳐 바로 가져다 쓰고 있습니다.\nQ . 앞으로 하시려고 하는 응용 영역들 몇 가지만 소개 하신다면 어떤 것이\nA . 크게 보면 가짜 뉴스든 탈세 선별이던 정보의 분류 문제이거든요. 정보가 어떤 범주가 있는지 그 범주를 주어지지 않고 풀 수도 있고 미리 정해 줄 수도 있고 그래서 사회 문제의 대부분은 정보의 분류 문제로 귀착이 되요. 특히, 도메인 전문가와 협업을 통해 분류의 알고리즘을 다양한 문제에 활용 가능합니다.\nQ . NIA가 '2022년도 인공지능 학습 데이터 구축사업'에서 '한국어 블렌더봇 데이터 구축 사업'을 심심이를 통해 진행되고 있는데 이번 과제에서는 어떤 자문을 하실 것인지...\nA . NIA 과제가 이제 시작했으니 어떻게 발전할지 저도 기대가 되는데요, 일단 제가 이 문제에 관심을 가지는 이유는 챗봇이 가지는 사회적 의미 때문이에요.\n아직은 챗봇과의 대화는 심심할 때나 외로울 때 등 다소 일상적이지 않은 상황이 많아요. 그런데 요즘 검색도 키워드에서 문장으로 하는 것을 보면 앞으로 챗봇에 더욱 익숙해지는 사회 분위기가 무루 익습니다.\n그리고 미래에는 챗봇의 활용이 놀라울 정도로 늘어날 것 같아요. 아마도 일생에서 사람이 가장 많이 한 대화 상대는 챗봇이 될 것 처럼요. 저는 그런 시대가 올 것이고 그렇기 때문에 지금의 NIA 사업이 정말 중요하다고 생각해요.\n단순 지식이 아니라 윤리 가이드에 대한 총체적 고민이니까요. 그런 면에서 정부 과제이지만 세련된 기획이 있었다고 보입니다. 해외에서는 아직 데이터셋에 대한 노력을 들이기보다는 데이터를 이미 보유하고 있는 플랫폼이 모델을 만드는 실정이거든요.\n메타도 블랜더 봇을 만들 수 있었던 이유는 페이스북이나 인스타그램 그 안에 담긴 포스팅에 달린 댓글과 반응 데이터가 쌓였기 때문이죠. 예를 들면, 좋아요 많이 달린 답변, 이건 좋은 대화라는 라벨링인 것이죠.\nQ . AI '이루다' 처럼 편견과 차별, 그리고 인공지능 윤리 문제는 기술의 발전과 더불어 늘 고민해야 하는 본질적 문제인데 이번 '한국형 블랜더봇'에서 방안은 ...\n<편집자 주>지난해 개인정보보호위원회는 지난해 인공지능 챗봇 서비스 이루다에 1억 330만원의 과징금과 과태료 등을 부과했는데 당시, 윤종인 개인정보위 위원장은 “이루다 건에 대한 처분 결과가 AI 기술 기업이 개인정보를 이용할 때에 올바른 개인정보 처리 방향을 제시하는 길잡이가 되고, 기업이 스스로 관리·감독을 강화해 나가는 계기가 되기를 바란다”라고 밝혔었다.\nA . 네 저는 그래서 이 챗봇이 제가 생각하는 미래 비전의 끝까지 가는 데 있어서 많이 과제가 있는데 가장 중요한 것이 혐오 표현등 비윤리의 처리이고, 이 문제가 작년 NIA 과제에서 다뤄졌습니다. 현재 랭귀지 모델들이 한 번 학습이 되면 그 상태로 대화를 하니까 지금 그 뒤에 바뀐 세상을 모르고 대화를 하는 거잖아요.\n그래서 실시간 검색이라든지 아니면 계속해서 업데이트해 하는 능력도 중요해지고, 오랜 기억도 중요해지죠. 또 페르소나 같은 개념도 되게 재미있는 콘셉트인 것 같아요.\n페르소나도 유동적일 필요가 있습니다. 딱 정해져 있기보다는 같이 얘기를 하면서 1년 뒤에는 챗봇도 변해 있어야지 늘 똑같이 대화를 하면은 얼마나 재미가 없겠어요. 그래서 뭔가 이렇게 발전해 나가는 어떤 모델이 있을 거다 생각합니다.\n그 모델들이 발전해 가려면 어떤 a형 타입 b형 타입 이런 걸 미리 만들어놔야 되는 것처럼 그렇게 그런 진보의 과정에서 저는 현재 다루려는 페르소나 개념이 굉장히 유용할 것 같아요.\n특히, 책임감 있는 방식으로 이러한 노력을 확대해 나가기 위해 언어학자, 사회학자, 윤리학자를 포함한 지속적인 협업과 검증을 통해 현재까지의 어떤 모델보다 실시간 정보와 거의 모든 주제에 대한 정교한 대화 등을 동시에 할 수 있는 성능이 뛰어나고 더 인간적인 느낌을 줄 수 있는 기반을 조성하겠습니다.\nQ . 사회적 윤리가 상대적이다 한다면 봇이 서비스하는 상대방이 어느 나라에 있거나 어느 문화권에 있느냐에 대한 대안은...\nA . 중요한 문제인 거죠. 이 모호한 경계에서 확실한 경계가 한 가지 있는데 그건 바로 어린이가 쓰는 영역입니다. 마지노선이 ‘어린이들이 쓸 수 있는 것인가?’ 라는 질문으로 바꾸면 많은 사람이 공감하는 기준이 세워집니다.\n이에 대해 먼저 해놓고 나머지는 이제 점진적으로 해야 될 것 같아요. 한국에서 해선 안 될 말과 미국에서 해선 안 될 말이 정말 틀리잖아요. 한국은 아직 차별금지법이 없으니까요.\nQ . 최근 구글 람다에 대한 이슈도 있지만, 살아있는 사람과 다름없이 AI가 무슨 의식이 있거나 무슨 감정이 있는 존재를 느끼게 될 건데 그게 언제쯤 올 거라고 생각하시는지\nA . 예를 들어, IBM의 디베이터 프로젝트만 해도 처음에 유치원 수준 이렇게 이렇게 문제를 주었는데, 인간하고 AI가 서로 토론을 해야 되는 거예요. 그래놓고 심사위원이 평가하는 거예요. 2019년까지는 IBS 디베이터가 대학생 수준의 토론이라고 평가 받았습니다. 이미 고등학생의 토론 수준을 넘어선 것으로 보입니다.\n이번에 람다도 그랬죠. 자기 감정적인 표현을 했고 가장 두려워하는 게 뭐냐 그랬더니 \"나를 정지시키는 거고 날 정지시키는 것은 나한테 죽음이다\" 이렇게 얘기하니까 쉽게 의식을 갖는 존재일 수 있다고 말한거죠.\n저는 그래서 아까하신 감정을 가진 AI가 나올 수 있는냐는 질문에 대해 충분히 가능하다고 저는 생각합니다.\nQ . 교수님 연구 목표 중에 하나가 '인간의 웰빙을 증진하고 사회적 가치를 반영하는 인공지능과의 대화를 위한 연구'를 하고 싶다고 하셨는데, 어떤 내용이신지\nA . 그동안은 목적 중심의 시스템이 있었던 것 같아요. 정보를 빨리 찾아주고 그리고 구글이나 이런 데서도 결과를 낼 때 사람들이 클릭을 많이 한 걸 보여주고 하지만 그 클릭이 어떤 의미를 가진 것인지 몰라요.\n놀라서 클릭한 건지 아니면 진짜 좋은 정보라고 생각을 했는지에 대한 컨텍스트가 없이 그냥 클릭 자체에만 관심을 가졌었죠. 마치 산업에 있어서도 경제 성장에 집중했던 시기가 있던 것처럼, 일단은 괜찮은 시스템을 만드는 데 집중을 했던 것 같아요.\n이제 경제 성장이 어느 정도 무르익었으니까, 우리가 도시에 나무도 심고 웰빙을 위한 여러 가치들을 넣는 것처럼 AI 시스템도 마찬가지로 이제 웰빙 가치를 넣어야 한다는 주장이 나오고 이런 실험들을 하고 있어요.\n예를 들어, 페이스북에서 랭킹을 할 때 단지 클릭을 해서가 아니고 사람들에게 인풋을 물어봅니다. 왜냐하면 사람들이 왜 했는지 이거를 의도를 파악을 해야 되는 거죠.\n사람의 행동과 원하는 건 다를 수 있거든요. 예를 들면, 나는 좀 더 애완동물을 많이 보고 싶어 하지만 갑자기 굉장히 잔인한 콘텐츠가 떴을 때 나도 모르게 클릭을 안 하더라도 0.25초 정도 화면을 안 움직이고 천천히 가면 그걸 기록을 해놔요.\n그렇죠 이 0.25초 봤다고 기록을 해놔요 기록을 다 해놓기 때문에 마치 내가 일부러 클릭을 안 했는데도 시스템은 다 아는 거예요.\n유튜브도 이제 그냥 틀어주잖아요 소리 없이 그걸 봤다 안 봤다를 다 기록을 하고 있는 거예요. 그러나 그게 내가 좋아서 한 게 아니라 그냥 보게 되는 것도 있단 말이에요. 그래서 이게 진짜 좋았는지를 다시 물어보는 그런 데이터들이 이제 쌓이게 되면은 점점 웰빙에 가까워지는 게 될 수 있는 것입니다.\n그 다음에 인공지능에 사회적 가치를 반영하자라는 것은, 요즘에 인증 얘기를 많이 좀 하고 있는 것 같은데요. 아무래도 사회적 가치를 인증해주는 혹은 사회적 가치 약간 정의해 주는 많은 기관들이 있을 것 같고 그게 KAIST 같은 기관일 수도 있고요.\n앞으로 사회적 웰빙이라는 것, 사회적 가치라는 것은 우리가 지금 어떤 다 기업마다 있잖아요. 예를 들어, SK가 원하는 가치가 있고 LG가 이루어 가는 가치가 있고, 각자 자기만의 어떤 브랜드의 가치가 있는 것처럼, 어떤 플랫폼들도 우리 플랫폼의 어떤 웰빙 가치는 이거예요 하고 셋업을 하고 그 가치에 맞는 어떤 서비스들이 나오게 될 거고 사람들은 그 가치를 보고 볼 것 같아요.\nQ . 지난달 21부터 24일까지 서울에서 컴퓨터 공학에서의 공정성, 책임성, 투명성에 대한 학제간 연구를 다루는 AI 윤리 분야에서는 가장 대표적인 국제 학회학회 'ACM FAccT 2022(ACM Conference on Fairness, Accountability, and Transparency)'가 개최됐는데...\nA . 저는 이번 행사에 패널 토론에서는 좌장과 기조연설로 '미래의 뉴스'는 어떻게 될지에 대해 발표했습니다. 좋은 융합의 장이 된 것 같습니다. 전산뿐만 아니라 법학, 노인학, 보건학, 윤리학 등 다양한 분야의 전문가들이 참석하셨습니다. 또 온라인과 오프라인으로 동시에 열려서 너무 좋았던 것 같습니다.\n이번 학회는 국내외 AI 윤리 분야의 전문가들이 대거 참여해, 초대규모 언어모델을 개발하고 실제 사용자들을 위한 서비스에 적용하는 과정에서 나타날 수 있는 윤리적 문제들에 대해 논의하고, 이런 문제를 해결하기 위한 해결책을 탐색하는 자리였습니다.\n특히, AI 모델이 데이터 학습에 있어 쉬운 방법을 선호하는 경향이 있는데, 이 때문에 발생하는 문제점 등을 분석하고 해결방안을 제시하는 등 이번 '한국어 블렌더봇 데이터 구축 사업'에 많은 도움이 된 것 같습니다.\nQ . DARPA에서도 설명가능한 인공지능(XAI) 과제에서 심리학 모델과 설명을 어떻게 해 주는 게 사람들이 잘 더 이해할 수 있는 설명 모듈로 만들 거냐 이런 연구가 있는데...\nA . 설명 가능성과 해석 가능성 이런 것이 너무 중요한 것 같아요. 기존의 AI 모델들이 지금까지는 사후 설명을 합니다. 결정을 블랙박스가 해놓고 왜 이렇게 했어 하고 이유를 그 뒤에 설명을 해주는 것인데요, 모델들을 보면 그 안에 의사결정 구조가 있거나 하는 형식이죠. 또 설명으로 내놓는 것은 주로 변수 값들인데 실무자 입장에서 이해하기 어려운 설명이죠. 변수가 이래서 알고리즘이 “이렇게 결정했어요” 라고 하면 대부분의 사람들은 거기서 만족을 한다는 실험 결과도 있기도 합니다.\n요즘에 새롭게 시도되는 연구들은 휴먼 로직과 비슷한 아예 해석가능성을 넣자고 하고 있어요. 인간처럼 생각하고 이해할 수 있는 AI인거이죠.\n그러나, 그 문제가 굉장히 어려운 이유가 처음에 설명으로 내놓을 이유의 갯수가 미지이기 때문이죠. 예를 들면, 가장 유용한 답변 3가지를 찾아라！ 라든지 명확한 목적이 주어지는데, 단지 몇개인지는 모르지만 사람이 납득할 이유를 주라는 목적이거든요.\n그럼에도 이 분야 논문들이 조금씩 NeurIPS 를 비롯한 학술대회에 나오고 있습니다. 휴먼 로직을 닮은 해석가능성 방법이 개발된다면 모든 분야에서 큰 영향을 끼칠 것이라 생각돼요. 컴퓨터 비전에도 다시 그 문제가 적용되고 자연어 처리(NLP)에도 적용될 거라 예상됩니다.\nQ . 마지막으로 이번 과기정통부와 NIA에서 심혈을 기울인 이번 '한국어 블렌더봇 데이터 구축'사업의 전망과 비전을 말씀해 주신다면...\nA . 물론, 어려움이 따르겠지만 우리는 한동안 개인정보 보호나 정제되지 않은 단어사용, 차별 또는 혐오 발언으로 이슈 한 가운데 있었던 지난해 AI 대화 모델 사태로 경험했듯이 이러한 문제를 사전에 통제하고 완화시켜야 하며 언어‧사회‧윤리학자 등을 포함한 지속적인 협업과 검증을 통해 관리·감독을 강화하는 등 한국어 블렌더봇 데이터 구축에 심혈을 기울여야 할 것입니다.\n이 데이터와 솔루션이 구축되면 인성, 공감, 지식과 같은 여러 대화 기술을 단일 시스템으로 결합한 국내 최초의 AI 챗봇으로 사람들과 대화할 때, 보다 다양한 세션에서 더 길고, 더 박식하며, 사실적으로 일관된 대화를 구사할 것이라 전망됩니다.\n특히, 대화중에 이 모델은 상황별 인터넷 검색 쿼리를 생성하고 결과를 읽고 사람들의 질문과 의견에 응답할 때 그 정보를 통합할 수 있다는 것입니다. 이것은 그 모델이 끊임없이 변화하는 세계에서 학습하고 최신 상태를 유지한다는 것을 의미합니다.\n즉, 이 모델은 사실적인 사실에 기반하고 자의적으로 추론하지 않는다는 것을 의미합니다. 어떤 주제에 대해서도 멀티세션 대화를 할 수 있고, 대화가 진화함에 따라 알고, 말할 수 있는 것을 더함으로써 우리 일상생활과 비지니스에 유용하게 사용될 수 있을 것으로 예상됩니다.",
    "tag": "csweb.news",
    "id": 219
}