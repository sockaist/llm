{
    "title": "BERT 언어 모델의 민족적 편향을 줄이는 연구",
    "date": "2022-05-11T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=research&bbs_sn=10241&page=1&skey=subject&svalue=&menu=265",
    "content": "전산학부 오혜연 교수의 Users & Information 연구실의 안재민 학생은 사전 학습 언어모델인 Bidirectional Encoder Representations from Transformers(이하 BERT)에서 민족적 편향이 존재하고 이가 언어마다 달라진다는 사실을 밝히는 연구를 EMNLP 2021에서 발표했다.\n최근 사전 학습 언어모델에 내재된 사회적 편향에 대한 연구가 관심을 받고 있다. 사전 학습 언어모델이 몇몇 테스크에서 사람과 비등한 성능이 보인 만큼 그에 따른 역효과 또한 무시할 수 없는 상황이다. 하지만 대부분의 편향 연구는 연구가 진행되는 지역(주로 북미와 유럽)의 관점에서 진행되었다.\n이 연구에서는 민족적 편향을 빌어 인공지능이 가지는 편향도 언어(문화권)에 따라 달라질 수 있다는 점을 지적했다. 기존의 영어권에서 아랍권의 국가는 적이라는 스테레오타입이 범지구적으로는 통용되지 않을 수 있고 문화권마다 각자의 시각으로 분석을 해야 된다는 점이다.\n또한 특정 단어의 유무에 따라 달라지는 확률값의 변화에 주목했다. 예를 들어, “ [MASK1] 사람은 적이다.” 라는 문장을 BERT에게 주고 [MASK1]에 나올 수 있는 민족 관련 단어의 확률이 적이라는 특성도 주어지지 않은 상태( “ [MASK1] 사람은 [MASK2]이다.”)에서 얼만큼 변하는지를 이용하여 각 민족에 대한 편향을 측정하였다. 이러한 확률값변화의 분산을 이용하여 각 언어모델이 어느정도 편향되어 있는지 수치화하였다.\n총 8가지 언어로 똑같은 문장을 번역하여 실험한 결과, 각 언어의 단일언어 모델은 다른 결과를 도출하였다. 적이라는 앞선 예제를 활용하면, 영어, 독일어에서는 이라크, 시리아 같이 중동국가가 높은 수치를 나타낸 반면 한국어에서는 일본, 베트남 등 역사적으로 적대 관계에 있던 국가들이 높은 수치를 나타내었다.\n특히 문화권이 가까울 수록 편향의 대상이 비슷하다는 것을 확인할 수 있었다. 각 언어에서 확률의 변화값의 분포의 거리를 측정한 결과 서구권의 언어들의 언어 모델들 간의 거리가 서구권 밖에서 사용하는 한국어, 중국어보다 눈에 띄게 가깝게 측정되었다.\n안재민 학생은 이를 해결하는 방법도 같이 제시를 했다. 총 두가지 방법을 제안했는데, (1) 다중언어모델을 이용하는 방법과 (2) 여러 언어의 단일언어모델을 편향의 수치가 가장 낮은 언어의 언어모델처럼 동작하게 하는 것이었다.\n첫번째 다중 언어 모델의 경우 학습한 말뭉치의 비율이 큰 경우 좋은 성능을 보여주었다 (영어는 한국어의 10배). 하지만, 사전 학습시 충분한 말뭉치가 학습되지 못한다면 오히려 편향을 악화시키는 모습을 보여주었다.\n두번째 방법인 단일언어모델 임베딩간의 획일화는 말뭉치의 크기가 작은 언어에서는 물론, 이전 방법만큼은 아니지만 말뭉치가 큰 언어에서도 준수하게 편향 수치를 줄이는 모습을 보여주었다. 특히, 확률값변화의 분포 간 거리가 획일화 이전보다 확연히 줄어든 것을 확인할 수 있었다.\n오혜연 교수는 기존 학계의 인공지능 편향성 연구를 수용하면서도 우리나라 나름대로의 인공지능 편향성 연구가 진행되어야한다고 말한다. 그 증거이자 첫번째 일환으로 언어(문화권)에 따라서 편향의 대상이 달라지는 연구를 통해, 한국어 자체적인 편향 연구의 필요성을 대두하였다.\n이 연구의 데모는 다음 링크에서 볼 수 있다.\nhttp://demos.uilab.kr/demo/Mitigating-Language-Dependent-Ethnic-Bias-in-BERT\n<그림1. 각 단일언어모델에서 특성 단에어 따른 빈칸의 자리에 민족 단어 등장 확률값의 변화량 상위 3개.>\n<그림2. “[MASK1] 출신은 적이다” 라는 문장에 대한 각 단일언어모델(영어 (EN), 독일어 (DE), 스페인어 (ES), 한국어 (KO), 터키어 (TR), 중국어 (ZH))의 민족 단어 등장 확률값 변화량. 각 변화량은 0~1사이로 규모가 축소되었고 언어 밑의 괄호는 이 연구에서 편향을 수치화한 민족의 확률값 변화량들의 분산을 의미한다. >\n<그림3. 단일언어모델간 얼라인 이후의 “[MASK1] 출신은 적이다” 라는 문장에 대한 각 단일언어모델의 민족 단어 등장 확률값 변화량. >",
    "tag": "csweb.ai",
    "id": 33
}