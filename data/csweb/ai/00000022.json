{
    "title": "소량의 데이터로 딥러닝 정확도 높이는 기술",
    "date": "2021-10-28T00:00:00Z",
    "link": "https://cs.kaist.ac.kr/board/view?bbs_id=research&bbs_sn=9919&page=1&skey=subject&svalue=&menu=265",
    "content": "● 훈련 데이터 부족 현상을 완화할 수 있는 새로운 시각 제시\n● 국제학술대회 '신경정보처리시스템학회 2021'서 발표 예정\n● 이미지 분류 문제서 최신 방법 대비 최대 12％ 정확도 향상\n최근 다양한 분야에서 심층 학습(딥러닝) 기술을 활용한 서비스가 급속히 증가하고 있다.\n서비스 구축을 위해서는 심층 학습 모델을 훈련해야 하며, 이를 위해서는 충분한 훈련 데이터를 준비해야 한다.\n특히 훈련 데이터에 정답지를 만드는 레이블링(labeling) 과정이 필요한데 (예를 들어, 낙타 사진에 '낙타'라고 정답을 적어줌), 이 과정은 일반적으로 수작업으로 진행되므로 엄청난 노동력과 시간이 소요된다.\n따라서 훈련 데이터가 충분하지 않은 상황을 효과적으로 타개하는 방법이 요구되고 있다.\n▲ 연구팀에서 개발한 비선호 특성 억제 방법론의 동작 개념도\n이런 가운데 KAIST가 소량의 데이터로 심층 학습(딥러닝) 정확도 향상 기술을 발표했다.\n▲ 왼쪽부터 KAIST 전산학부 이재길 교수, 박동민 박사과정\nKAIST 전산학부 이재길 교수 연구팀이 적은 양의 훈련 데이터가 존재할 때도 높은 예측 정확도를 달성할 수 있는 새로운 모델 훈련 기술을 개발했다.\n이 교수팀이 개발한 기술은 심층 학습 모델의 훈련에서 바람직하지 않은 특성을 억제해 충분하지 않은 훈련 데이터를 가지고도 높은 예측 정확도를 달성할 수 있게 해준다.\n바람직하지 않은 특성을 억제하기 위해서 분포 外(out-of-distribution) 데이터를 활용한다. 예를 들어, 낙타와 호랑이 사진의 분류를 위한 훈련 데이터에 대해 여우 사진은 분포 외 데이터가 된다.\n이때 이 교수팀이 착안한 점은 훈련 데이터에 존재하는 바람직하지 않은 특성은 분포 외 데이터에도 존재할 수 있다는 점이다.\n즉 위의 예에서 여우 사진의 배경으로도 사막이 나올 수 있다. 따라서 다량의 분포 외 데이터를 추가로 활용해 여기에서 추출된 특성은 영(0) 벡터가 되도록 심층 학습 모델의 훈련 과정을 규제해 바람직하지 않은 특성의 효과를 억제한다.\n훈련 과정을 규제한다는 측면에서 정규화 방법론의 일종이라 볼 수 있다. 분포 외 데이터는 쓸모없는 것이라 여겨지고 있었으나, 이번 기술에 의해 훈련 데이터 부족을 해소할 수 있는 유용한 보완재로 탈바꿈될 수 있다.\n연구팀은 이 정규화 방법론을 '비선호(比選好) 특성 억제'라고 이름 붙이고 이미지 데이터 분석의 세 가지 주요 문제에 적용했다.\n그 결과 기존 최신 방법론과 비교했을 때 이미지 분류 문제에서 최대 12％ 예측 정확도를, 객체 검출 문제에서 최대 3％ 예측 정확도를, 객체 지역화 문제에서 최대 8％ 예측 정확도를 향상했다.\n1 저자인 박동민 박사과정 학생은 \"이번 기술은 훈련 데이터 부족 현상을 해결할 수 있는 새로운 방법\"이라면서 \"분류, 회귀 분석을 비롯한 다양한 기계 학습 문제에 폭넓게 적용될 수 있어, 심층 학습의 전반적인 성능 개선에 기여할 수 있다\"고 밝혔다.\n연구팀을 지도한 이재길 교수도 \"이 기술이 텐서플로우(TensorFlow) 혹은 파이토치(PyTorch)와 같은 기존의 심층 학습 라이브러리에 추가되면 기계 학습 및 심층 학습 학계에 큰 파급효과를 낼 수 있을 것이다\"고 말했다.\nKAIST 지식서비스공학대학원에 재학 중인 박동민 박사과정 학생이 1 저자, 송환준 박사, 김민석 박사과정 학생이 2, 3 저자로 각각 참여한 이번 연구는 최고권위 국제학술대회 '신경정보처리시스템학회(NeurIPS) 2021'에서 올 12월 발표될 예정이다.\n출처 : 충청일보(https://www.ccdailynews.com)",
    "tag": "csweb.ai",
    "id": 34
}