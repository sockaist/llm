from src.utils.chain import RouterChain, LLMChain
from src.utils.chatbot import ChatBot
from src.utils.output_parsers import JSONOutputParser
from src.utils.prompt import InstructionConfig
import google.generativeai as genai
from typing import Dict, Any, List, Optional
import json
import os
from datetime import datetime

class InputChecker:
    """
    Checks and validates user input using a chatbot powered by the Google Gemini API.
    This class loads configuration from a JSON file and uses a chatbot to process and validate user queries.
    """
    def __init__(self, api_key: str, config_file_path: str = None):
        """
\ã…£
        Args:
            api_key (str): Google API í‚¤
        """
        self.api_key = api_key
        genai.configure(api_key=self.api_key)

        # JSON ì¶œë ¥ íŒŒì„œ ìƒì„±
        self.json_parser = JSONOutputParser()
        
        # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if config_file_path is None:
            config_file_path = os.path.join(os.path.dirname(__file__), "/Users/bagjimin/Desktop/project/chatbot/src/backend/src/llm/utils_json/inputchecker.json")

        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.checker_config = InstructionConfig(
            instruction=config['instruction'],
            output_parser=self.json_parser,
            output_format=config['output_format'],
            examples=config['examples']
        )

        self.checker = ChatBot(
                    model_name="gemini-2.0-flash",
                    temperature=0.5,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
                    max_output_tokens=1024,
                    instruction_config=self.checker_config,
                    api_key=self.api_key
                )

    def process_query(self, user_message: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬

        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            Dict[str, Any]: ìƒë‹´ ì‘ë‹µ
        """
        # ì±—ë´‡ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if not self.checker.is_running():
            self.checker.start_chat()

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬
        response = self.checker.send_message(user_message)

        # ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(response, dict):
            try:
                response = json.loads(response)
            except:
                return {
                    "is_valid": False,
                    "reason": "ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "response": response
                }

        return response

class InputNormalizer:
    def __init__(self, api_key: str, config_file_path: str = None):
        """

        Args:
            api_key (str): Google API í‚¤
            config_file_path (str): ì„¤ì • JSON íŒŒì¼ ê²½ë¡œ
        """
        self.api_key = api_key
        genai.configure(api_key=self.api_key)

        # JSON ì¶œë ¥ íŒŒì„œ ìƒì„±
        self.json_parser = JSONOutputParser()
        
        # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if config_file_path is None:
            config_file_path = os.path.join(os.path.dirname(__file__), "/Users/bagjimin/Desktop/project/chatbot/src/backend/src/llm/utils_json/inputNormalizer.json")

        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)


        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.normalizer_config = InstructionConfig(
            instruction=config['instruction'],
            output_parser=self.json_parser,
            output_format=config['output_format'],
            examples=config['examples']
        )
        self.normalizer = ChatBot(
                    model_name="gemini-2.0-flash",
                    temperature=0.5,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
                    max_output_tokens=1024,
                    instruction_config=self.normalizer_config,
                    api_key=self.api_key
                )

    def process_query(self, user_message: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬

        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            Dict[str, Any]: ìƒë‹´ ì‘ë‹µ
        """
        # ì±—ë´‡ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if not self.normalizer.is_running():
            self.normalizer.start_chat()

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬
        response = self.normalizer.send_message(user_message)

        # ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(response, dict):
            try:
                response = json.loads(response)
            except:
                return {
                    "is_valid": False,
                    "reason": "ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "response": response
                }

        return response


class QueryMaker:
    def __init__(self, api_key: str, config_file_path: str = None):
        """

        Args:
            api_key (str): Google API í‚¤
        """
        self.api_key = api_key
        genai.configure(api_key=self.api_key)

        # JSON ì¶œë ¥ íŒŒì„œ ìƒì„±
        self.json_parser = JSONOutputParser()
        
        # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if config_file_path is None:
            config_file_path = os.path.join(os.path.dirname(__file__), "/Users/bagjimin/Desktop/project/chatbot/src/backend/src/llm/utils_json/queryMaker.json")

        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)


        # ì¿¼ë¦¬ ì œì‘ì
        # ì¿¼ë¦¬ ì œì‘ì
        # ì¿¼ë¦¬ ì œì‘ì
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.query_maker_config = InstructionConfig(
            instruction=config['instruction'],
            output_parser=self.json_parser,
            output_format=config['output_format'],
            examples=config['examples']
        )

        self.query_maker = ChatBot(
                    model_name="gemini-2.0-flash",
                    temperature=0.5,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
                    max_output_tokens=1024,
                    instruction_config=self.query_maker_config,
                    api_key=self.api_key
                )

    def process_query(self, user_message: str) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬

        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            Dict[str, Any]: ìƒë‹´ ì‘ë‹µ
        """
        # ì±—ë´‡ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if not self.query_maker.is_running():
            self.query_maker.start_chat()

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬
        response = self.query_maker.send_message(user_message)

        # ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(response, dict):
            try:
                response = json.loads(response)
            except:
                return {
                    "is_valid": False,
                    "reason": "ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "response": response
                }

        return response
    
class FilterGenerator:
    def __init__(self, api_key: str, config_file_path: str = None):
        """
        í•„í„° ìƒì„±ì ì±—ë´‡ ì´ˆê¸°í™”

        Args:
            api_key (str): Google API í‚¤
        """
        self.api_key = api_key
        genai.configure(api_key=self.api_key)

        # JSON ì¶œë ¥ íŒŒì„œ ìƒì„±
        self.json_parser = JSONOutputParser()

        # ì˜¤ëŠ˜ ë‚ ì§œ ê°€ì ¸ì˜¤ê¸°
        today = datetime.now().strftime("%Y-%m-%d")
        
        # ê¸°ë³¸ ì„¤ì • íŒŒì¼ ê²½ë¡œ ì„¤ì •
        if config_file_path is None:
            config_file_path = os.path.join(os.path.dirname(__file__), "/Users/bagjimin/Desktop/project/chatbot/src/backend/src/llm/utils_json/filterGenerator.json")

        # ì„¤ì • íŒŒì¼ ë¡œë“œ
        with open(config_file_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # í•„í„° ìƒì„±ì ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.filter_generator_config = InstructionConfig(
            instruction=f"""ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ KAIST(í•œêµ­ê³¼í•™ê¸°ìˆ ì›) ì „ì‚°í•™ë¶€ ì±—ë´‡ íŒŒì´í”„ë¼ì¸ì˜ ì¼ë¶€ë¡œ, ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì •ë³´ ê²€ìƒ‰ì„ ìœ„í•œ í•„í„°ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

            ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢í ìˆ˜ ìˆëŠ” íŠ¹ì • ê¸°ê°„(ì‹œì‘ ë‚ ì§œì™€ ë ë‚ ì§œ)ê³¼ ìµœëŒ€ 3ê°œì˜ í•„í„° ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

            - ê¸°ê°„ì€ 'YYYY-MM-DD' í˜•ì‹ì˜ ì‹œì‘ ë‚ ì§œì™€ ë ë‚ ì§œë¡œ í‘œí˜„í•´ì•¼ í•©ë‹ˆë‹¤. ë§Œì•½ ê¸°ê°„ì´ ëª…í™•íˆ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ê¸°ê°„ í•„ë“œëŠ” Noneìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            - í•„í„° ë‹¨ì–´ëŠ” ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì¤‘ìš”í•œ í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œí•˜ë©°, ìµœëŒ€ 3ê°œê¹Œì§€ ì¶”ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•„í„° ë‹¨ì–´ê°€ ì—†ë‹¤ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

            JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
            """,
            output_parser=self.json_parser,
            output_format=config['output_format'],
            examples=config['examples']
        )

        self.filter_generator = ChatBot(
            model_name="gemini-2.0-flash",
            temperature=0.5,  # ì¼ê´€ëœ ì‘ë‹µì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„ ì„¤ì •
            max_output_tokens=1024,
            instruction_config=self.filter_generator_config,
            api_key=self.api_key
        )

    def process_query(self, user_message: str) -> Dict[str, Optional[Any]]:
        """
        ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ì—¬ í•„í„° ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            user_message (str): ì‚¬ìš©ì ë©”ì‹œì§€

        Returns:
            Dict[str, Optional[Any]]: ì¶”ì¶œëœ í•„í„° ì •ë³´ (ì‹œì‘ ë‚ ì§œ, ë ë‚ ì§œ, í•„í„° ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸)
        """
        # ì±—ë´‡ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë©´ ì‹œì‘
        if not self.filter_generator.is_running():
            self.filter_generator.start_chat()

        # ì‚¬ìš©ì ë©”ì‹œì§€ ì²˜ë¦¬
        response = self.filter_generator.send_message(user_message)

        # ì‘ë‹µì´ ë”•ì…”ë„ˆë¦¬ê°€ ì•„ë‹ˆë©´ ë³€í™˜
        if not isinstance(response, dict):
            try:
                response = json.loads(response)
            except:
                return {
                    "start_date": None,
                    "end_date": None,
                    "filter_words":'',
                    "reason": "ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜",
                    "message": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "response": response
                }

        return response

# ë¼ìš°í„° í•¨ìˆ˜: ì…ë ¥ëœ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•´ë‹¹ ë„ë©”ì¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
def router_func(inputs):
    query = inputs.get("query", "").lower()
    if "ë‚ ì”¨" in query:
        return "weather"
    elif "ë‰´ìŠ¤" in query:
        return "news"
    else:
        return "general"

# [ë‚ ì”¨ ì²´ì¸] - ì‚¬ìš©ìê°€ 'ë‚ ì”¨'ì™€ ê´€ë ¨ëœ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.
weather_prompt = InstructionConfig(
    instruction="ì§€ì—­ê³¼ ê´€ë ¨ëœ ë‚ ì”¨ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”: {query}",
    input_variables=["query"]
)
weather_chatbot = ChatBot(system_instruction="ë‹¹ì‹ ì€ ë‚ ì”¨ ì •ë³´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
weather_chain = LLMChain(
    chatbot=weather_chatbot,
    prompt=weather_prompt,
    output_key="response"
)

# [ë‰´ìŠ¤ ì²´ì¸] - ì‚¬ìš©ìê°€ 'ë‰´ìŠ¤'ì— ê´€í•œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ì‹¤í–‰ë©ë‹ˆë‹¤.
news_prompt = InstructionConfig(
    instruction="ìµœì‹  ë‰´ìŠ¤ë¥¼ ìš”ì•½í•˜ì—¬ ì œê³µí•´ì£¼ì„¸ìš”: {query}",
    input_variables=["query"]
)
news_chatbot = ChatBot(system_instruction="ë‹¹ì‹ ì€ ë‰´ìŠ¤ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.")
news_chain = LLMChain(
    chatbot=news_chatbot,
    prompt=news_prompt,
    output_key="response"
)

# [ì¼ë°˜ ì²´ì¸] - ê·¸ ì™¸ì˜ ì§ˆë¬¸ì— ëŒ€í•´ ê¸°ë³¸ì ì¸ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
general_prompt = InstructionConfig(
    instruction="ì¼ë°˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”: {query}",
    input_variables=["query"]
)
general_chatbot = ChatBot(system_instruction="ë‹¹ì‹ ì€ ì¹œì ˆí•œ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.")
general_chain = LLMChain(
    chatbot=general_chatbot,
    prompt=general_prompt,
    output_key="response"
)

# RouterChain ìƒì„±: ë¼ìš°í„° í•¨ìˆ˜ì™€ ê° ë„ë©”ì¸ë³„ ì²´ì¸ì„ ì—°ê²°í•©ë‹ˆë‹¤.
router_chain = RouterChain(
    router_func=router_func,
    destination_chains={
        "weather": weather_chain,
        "news": news_chain,
        "general": general_chain
    }
)

# ì±—ë´‡ ì‹¤í–‰ í•¨ìˆ˜
def run_chatbot():
    print("ë‹¤ì–‘í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë¼ìš°í„° ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!")
    while True:
        user_input = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” ('ì¢…ë£Œ' ì…ë ¥ ì‹œ ì¢…ë£Œ): ")
        if user_input.lower() == "ì¢…ë£Œ":
            break
        result = router_chain.run({"query": user_input})
        print("ì±—ë´‡ ë‹µë³€:", result["response"])

def main():
 # 1) Google Gemini API í‚¤ ì„¤ì •
    api_key = "YOUR_GOOGLE_GEMINI_API_KEY"

    # 2) ì±—ë´‡ ë‹¨ê³„ë³„ í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    checker     = InputChecker(api_key)
    normalizer  = InputNormalizer(api_key)
    querier     = QueryMaker(api_key)
    filterer    = FilterGenerator(api_key)

    print("=== ì±—ë´‡ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤! ===")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ' í˜¹ì€ 'exit'ì„ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        user_input = input("ì‚¬ìš©ì: ")
        if user_input.lower() in ("ì¢…ë£Œ", "exit", "quit"):
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ë‹¤ìŒì— ë˜ ë§Œë‚˜ìš”! ğŸ‘‹")
            break

        # 3) input ê²€ì¦
        check_result = checker.process_query(user_input)
        print("\n[ì…ë ¥ ê²€ì¦]")
        print(check_result)

        # 4) input ì •ê·œí™”
        norm_result = normalizer.process_query(user_input)
        print("\n[ì…ë ¥ ì •ê·œí™”]")
        print(norm_result)

        # 5) ì¿¼ë¦¬ ìƒì„±
        query_result = querier.process_query(user_input)
        print("\n[ì¿¼ë¦¬ ìƒì„±]")
        print(query_result)

        # 6) í•„í„° ìƒì„±
        filter_result = filterer.process_query(user_input)
        print("\n[í•„í„° ìƒì„±]")
        print(filter_result)

        print("\n" + "="*40 + "\n")

if __name__ == "__main__":
    main()